{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d8c47-2228-4b93-ab3e-5ca4b1ee80ef",
   "metadata": {},
   "source": [
    "2. for sanity checks, only track model as a hyperparam, add multiclass clustering\n",
    "3. add images\n",
    "4. for mnists need to create a hyperparam set for mlp, cnn and rbfs\n",
    "   - rbfs have three params, x, y and color val for images\n",
    "   - rbf hyper params -- clustering algorithms, rbf width, covariance calc\n",
    "   - mlp -- distribution between width and depth, online and minibatch and batch, \n",
    "   - cnn -- stride and padding, dialation, activation funcs\n",
    "5. for fashion mnist, use optimal settings, and different hyperparam sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tools\\Anaconda3\\envs\\mynn\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.utils.tensorboard as tb\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "import display\n",
    "import models\n",
    "import general_torch as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a15719395ed2df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# init invariants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float\n",
    "\n",
    "# df = display.initialize_class_dataframe()\n",
    "experiment_directory = f'experiments/cluster/mlp'\n",
    "\n",
    "invariable_dict = {\n",
    "  'data_path': 'cluster_dict.pt',\n",
    "  'exp_file': experiment_directory,\n",
    "  'model_type': 'classification',\n",
    "  'device': device,\n",
    "  'data_type': dtype,\n",
    "  'run': None,\n",
    "  'model': 'mlp2_4',\n",
    "  'init_num': '0',\n",
    "  'optim': 'sgd',\n",
    "  'optim_dict': {'lr': 0.1, 'momentum': 0.4},\n",
    "  'error_f': 'bce',\n",
    "  'stop_dict': {'criteria': 'epoch', 'stop_val': 100, 'max_epochs': 100},\n",
    "  'dl_dict': {'batch_size': 1, 'shuffle': True},\n",
    "  'seed': 42,\n",
    "  'hparams': None,\n",
    "}\n",
    "\n",
    "cwd = os.getcwd()\n",
    "exp_dir = os.path.join(cwd, experiment_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f170b65b-aebf-4840-a61d-6838deeb3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "\n",
    "file_tensor = os.path.join(cwd, f'data/{invariable_dict[\"data_path\"]}')\n",
    "\n",
    "dict_tensor = torch.load(file_tensor)\n",
    "\n",
    "train_data = dict_tensor['train_data'].to(device).to(dtype)\n",
    "train_label = dict_tensor['train_label'].to(device).to(dtype)\n",
    "\n",
    "valid_data = dict_tensor['valid_data'].to(device).to(dtype)\n",
    "valid_label = dict_tensor['valid_label'].to(device).to(dtype)\n",
    "\n",
    "test_data = dict_tensor['test_data'].to(device).to(dtype)\n",
    "test_label = dict_tensor['test_label'].to(device).to(dtype)\n",
    "\n",
    "# todo in future init this in data init\n",
    "class_labels = [i for i in range(int(dict_tensor['num_classes']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e9f2fd-3a39-44bb-a0c6-5ee08bc4800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data class and data sets\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self, train, label):\n",
    "    self.data = train\n",
    "    self.label = label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.label[idx]\n",
    "\n",
    "\n",
    "train_set = Data(train_data, train_label)\n",
    "valid_set = Data(valid_data, valid_label)\n",
    "test_set = Data(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0460e9-da86-41c3-92a7-3dc87e64f535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"combined_hparams = [\\n  {'optim_dict': opt, 'dl_dict': dl, 'error_f': err}\\n  for opt, dl, err in itertools.product(hparam1['optim_dict'])\\n]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use itertools to generate hparam dictionaries\n",
    "\n",
    "hparam1 = {'model':invariable_dict['model']}\n",
    "combined_hparams = [hparam1]\n",
    "\n",
    "'''combined_hparams = [\n",
    "  {'optim_dict': opt, 'dl_dict': dl, 'error_f': err}\n",
    "  for opt, dl, err in itertools.product(hparam1['optim_dict'])\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c18b50-8008-461f-9094-c515225fd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using combined hparams and the invariable base dict, create\n",
    "# run dict\n",
    "\n",
    "run_dict = {}\n",
    "for run, hparam_dict in enumerate(combined_hparams):\n",
    "  new_dict = {**invariable_dict, **hparam_dict}\n",
    "  new_dict['hparams'] = hparam_dict\n",
    "  new_dict['run'] = 0\n",
    "  dict_pair = {run: new_dict}\n",
    "  run_dict.update(dict_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f18e03-3573-4ec3-bb89-7fc674a20ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo in main script, replace this with an encapsulating loop, right now keep it simple\n",
    "# init loop variables\n",
    "\n",
    "exp = run_dict[0]\n",
    "\n",
    "# init log path for this run\n",
    "log = os.path.join(exp_dir, f\"run{exp['run']}\")\n",
    "\n",
    "# always start by resetting seeds before initializing anythin  g\n",
    "gt.init_seeds(exp['seed'], exp['device'])\n",
    "\n",
    "# prep dataloader, use kwargs to init\n",
    "\n",
    "train_loader = DataLoader(train_set, **exp['dl_dict'])\n",
    "valid_loader = DataLoader(valid_set, **exp['dl_dict'])\n",
    "test_loader = DataLoader(test_set, **exp['dl_dict'])\n",
    "\n",
    "# build model / load state dict / load whole model / explicitly init param weights\n",
    "\n",
    "model_path = f\"{exp['model']}_{exp['init_num']}\"\n",
    "\n",
    "model = models.get_model(exp['model'])()\n",
    "model.load_state_dict(models.load_init_model(model_path))\n",
    "model.to(exp['data_type'])\n",
    "model.to(exp['device'])\n",
    "\n",
    "optim = gt.get_optim(exp['optim'])(model.parameters(), **exp['optim_dict'])\n",
    "error = gt.get_error(exp['error_f'])()\n",
    "\n",
    "profile_model = models.get_model(exp['model'])()\n",
    "profile_model.load_state_dict(models.load_init_model(model_path))\n",
    "profile_model.to(exp['data_type'])\n",
    "profile_model.to(exp['device'])\n",
    "profile_train_loader = DataLoader(train_set, **exp['dl_dict'])\n",
    "\n",
    "# writer doesnt like interior dicts, get rid of them in hparams\n",
    "\n",
    "format_hparams = {**exp['hparams']}\n",
    "\n",
    "for key, value in format_hparams.items():\n",
    "  if isinstance(value, dict):\n",
    "    format_hparams[key] = json.dumps(value)\n",
    "\n",
    "# init tensorboard writer\n",
    "train_writer = tb.writer.SummaryWriter(log_dir=log)\n",
    "test_writer = tb.writer.SummaryWriter(log_dir=os.path.join(log, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacbd33c-9aa4-4a02-b563-0634ebd8d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with torch.inference_mode():\\n  for batch_idx, (data, target) in enumerate(train_loader):\\n    model(test_data)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for runtime errors / init predictions should be part of data collection loop\n",
    "'''for i in model.parameters():\n",
    "    print(i.dtype)\n",
    "    break\n",
    "print(test_data.dtype)'''\n",
    "\n",
    "'''with torch.inference_mode():\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    model(test_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca024de-c7a8-417e-bd1d-7d39b41b22fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.75\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 12\u001b[0m   pred \u001b[38;5;241m=\u001b[39m model(data, alpha)\n\u001b[0;32m     13\u001b[0m   loss \u001b[38;5;241m=\u001b[39m error(pred, target)\n\u001b[0;32m     14\u001b[0m   optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\mynn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\mynn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\mynn\\nn_project_1\\sanity\\models.py:81\u001b[0m, in \u001b[0;36mnewclass.forward\u001b[1;34m(self, x, alpha)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, alpha):\n\u001b[1;32m---> 81\u001b[0m   x \u001b[38;5;241m=\u001b[39m CustomSigmoid\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x), alpha)\n\u001b[0;32m     82\u001b[0m   x \u001b[38;5;241m=\u001b[39m CustomSigmoid\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x), alpha)\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\mynn\\nn_project_1\\sanity\\models.py:91\u001b[0m, in \u001b[0;36mCustomSigmoid.forward\u001b[1;34m(ctx, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 91\u001b[0m     ctx\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m alpha\n\u001b[0;32m     92\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mctx\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# profile model\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             schedule=torch.profiler.schedule(wait=5, warmup=4, active=1, repeat=1),\n",
    "             on_trace_ready=torch.profiler.tensorboard_trace_handler(os.path.join(log, 'model_profiles')),\n",
    "             record_shapes=True,\n",
    "             with_stack=True,\n",
    "             profile_memory=True) as prof:\n",
    "  with record_function('training'):\n",
    "    alpha = .75\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      pred = model(data, alpha)\n",
    "      loss = error(pred, target)\n",
    "      optim.zero_grad()\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      prof.step()\n",
    "      alpha = model.newclass.loopalpha(batch_idx)\n",
    "      if batch_idx == 9:\n",
    "        break\n",
    "\n",
    "  with record_function('inference'):\n",
    "    alpha = 1\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      model(data, alpha)\n",
    "      prof.step()\n",
    "      if batch_idx == 9:\n",
    "        train_writer.add_graph(model, data)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961cf00-7963-4ee7-a6a7-fc7ba76f5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init test predictions, to test overall improvement, only needed if model reuse\n",
    "\n",
    "'''with torch.inference_mode():\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        preds = model(data)\n",
    "        loss = error(preds, target)\n",
    "        pred_list.append(preds)\n",
    "        target_list.append(target)\n",
    "        total += loss\n",
    "    avg_error = total / len(test_data)\n",
    "    gt.write_test_info(exp, train_writer, target_list, pred_l\n",
    "ist, avg_error)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c20a3-0ef0-4647-aec0-30f3e1d831ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify hyperparams, only for model reuse\n",
    "\n",
    "'''modify_hyper = False\n",
    "if modify_hyper:\n",
    "    epochs = 10\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=0.001, mom\n",
    "entum=0.4)\n",
    "    error = torch.nn.MSELoss()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9bde5-601d-4507-9430-a9bdea5026ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train and valid, log every epoch\n",
    "\n",
    "error_last = None\n",
    "for epoch in range(exp['stop_dict']['max_epochs']):\n",
    "  model.train()\n",
    "  total = 0\n",
    "  target_list = []\n",
    "  pred_list = []\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    pred = model(data)\n",
    "    loss = error(pred, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    total += loss\n",
    "    target_list.append(target)\n",
    "    pred_list.append(pred)\n",
    "  avg_error = total / len(train_data)\n",
    "  display.write_classification_train_info(train_writer, model, target_list, pred_list, avg_error, 'train', epoch)\n",
    "\n",
    "  model.eval()\n",
    "  error_new = None\n",
    "  total = 0\n",
    "  target_list = []\n",
    "  pred_list = []\n",
    "  for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "    pred = model(data)\n",
    "    error_new = error(pred, target)\n",
    "    total += error_new\n",
    "    target_list.append(target)\n",
    "    pred_list.append(pred)\n",
    "    avg_error = total / len(valid_data)\n",
    "  display.write_classification_train_info(train_writer, model, target_list, pred_list, avg_error, 'valid', epoch)\n",
    "\n",
    "  if exp['stop_dict']['criteria'] == 'error_change':\n",
    "    if error_last is not None and error_new / error_last < exp['stop_val']:\n",
    "      break\n",
    "    else:\n",
    "      error_last = error_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3c84e-c861-49c4-98d5-57131019835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run final inference\n",
    "\n",
    "with torch.inference_mode():\n",
    "  pred_tensor_list = []\n",
    "  target_tensor_list = []\n",
    "  total = 0\n",
    "  for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    preds = model(data)\n",
    "    loss = error(preds, target)\n",
    "    pred_tensor_list.append(preds)\n",
    "    target_tensor_list.append(target)\n",
    "    total += loss\n",
    "  avg_error = total / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476bb68-dd22-4a6b-bb79-954c5ad1eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensors to lists\n",
    "\n",
    "t = torch.stack(target_tensor_list, dim=0).squeeze()\n",
    "p = torch.stack(pred_tensor_list, dim=0).squeeze()\n",
    "target_tensor = torch.argmax(t, dim=1)\n",
    "pred_tensor = torch.argmax(p, dim=1)\n",
    "target_list = target_tensor.tolist()\n",
    "pred_list = pred_tensor.tolist()\n",
    "cm = display.plot_multiclass_confusion_matrix(target_list, pred_list, class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3652d9-a801-4be2-9edc-7439e79b90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb825b-65cf-48cf-904c-613fe3c21c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(display)\n",
    "decision_boundary = display.plot_decision_boundary(exp, model, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e7d2252-0a7a-4273-88ef-b5c38a1f54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do final tensorboard run write\n",
    "# save preds, labels and state dict\n",
    "# write test info into db\n",
    "\n",
    "file_dir = {'preds': pred_list, 'lables': target_list,\n",
    "            'state_dict': model.state_dict(), }\n",
    "filename = os.path.join(log, 'model_info.pkl')\n",
    "\n",
    "with open(filename, \"wb\") as file:\n",
    "  pickle.dump(file_dir, file)\n",
    "\n",
    "train_writer.add_figure('test/confusion_matrix', cm)\n",
    "train_writer.add_figure('test/decision_boundary', decision_boundary)\n",
    "display.write_classification_test_info(test_writer, format_hparams, target_list, pred_list, avg_error)\n",
    "# train_writer.add_pr_curve('test/precision_recall_curve', target_tensor, pred_tensor, 0)\n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274dff9-377b-4902-a2f8-deb66cd50b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2ddc4-56f8-43c2-964c-63252e7b84bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
