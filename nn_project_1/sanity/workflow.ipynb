{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d8c47-2228-4b93-ab3e-5ca4b1ee80ef",
   "metadata": {},
   "source": [
    "1. add ipy_checkpoints and pycache to git ignroe and push\n",
    "2. generalize all functions ie the models, and data writers to handle all batch transformations\n",
    "3. after rbf, test all setups on collab\n",
    "3. add images\n",
    "4. mnist\n",
    "   add image func for what you get wrong\n",
    "5. for fashion mnist, use optimal settings, and different hyperparam sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.utils.tensorboard as tb\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "import display\n",
    "import models\n",
    "import general_torch as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a15719395ed2df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# init invariants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "# THESE ARE THE THINGS YOU CHANGE\n",
    "# UPDATE MODELS\n",
    "# INIT MODEL\n",
    "# INIT CONTROL AND INVARIANTS\n",
    "write = True\n",
    "preprocess = False\n",
    "experiment_directory = f'experiments/cluster/mlp'\n",
    "data_path = 'cluster_dict.pt'\n",
    "# model is module chain, id, output\n",
    "model = 'mlp1_4'\n",
    "\n",
    "invariable_dict = {\n",
    "  'data_path': data_path,\n",
    "  'exp_dir': experiment_directory,\n",
    "  'model_type': 'classification',\n",
    "  'device': device,\n",
    "  'data_type': dtype,\n",
    "  'run': None,\n",
    "  'model': model,\n",
    "  'init_num': '0',\n",
    "  'optim': 'sgd',\n",
    "  'optim_dict': {'lr': 0.1, 'momentum': 0.4},\n",
    "  'error_f': 'bce',\n",
    "  'stop_dict': {'criteria': 'epoch', 'stop_val': 0.001, 'max_epochs': 100}, # early stop\n",
    "  'dl_dict': {'batch_size': 1, 'batch_type':'fixed', 'shuffle': True},  # batch should be a fraction\n",
    "  'pre_dict': {\n",
    "      'centers': 5,\n",
    "      'sigma': 1,\n",
    "      'cluster_algor': 'kmean',\n",
    "      'rbf_init': None,\n",
    "  },\n",
    "  'seed': 42,\n",
    "  'hparams': None,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f170b65b-aebf-4840-a61d-6838deeb3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "\n",
    "file_tensor = os.path.join(cwd, f'data/{invariable_dict[\"data_path\"]}')\n",
    "\n",
    "dict_tensor = torch.load(file_tensor)\n",
    "\n",
    "train_data = dict_tensor['train_data'].to(device).to(dtype)\n",
    "train_label = dict_tensor['train_label'].to(device).to(dtype)\n",
    "\n",
    "valid_data = dict_tensor['valid_data'].to(device).to(dtype)\n",
    "valid_label = dict_tensor['valid_label'].to(device).to(dtype)\n",
    "\n",
    "test_data = dict_tensor['test_data'].to(device).to(dtype)\n",
    "test_label = dict_tensor['test_label'].to(device).to(dtype)\n",
    "\n",
    "# todo in future init this in data init\n",
    "class_labels = [i for i in range(int(dict_tensor['num_classes']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e9f2fd-3a39-44bb-a0c6-5ee08bc4800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data class and data sets\n",
    "\n",
    "class Data(Dataset):\n",
    "  def __init__(self, train, label):\n",
    "    self.data = train\n",
    "    self.label = label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.label[idx]\n",
    "\n",
    "\n",
    "train_set = Data(train_data, train_label)\n",
    "valid_set = Data(valid_data, valid_label)\n",
    "test_set = Data(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0460e9-da86-41c3-92a7-3dc87e64f535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"combined_hparams = [\\n  {'optim_dict': opt, 'dl_dict': dl, 'error_f': err}\\n  for opt, dl, err in itertools.product(hparam1['optim_dict'])\\n]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use itertools to generate hparam dictionaries\n",
    "\n",
    "hparam1 = {'model':invariable_dict['model']}\n",
    "combined_hparams = [hparam1]\n",
    "\n",
    "'''combined_hparams = [\n",
    "  {'optim_dict': opt, 'dl_dict': dl, 'error_f': err}\n",
    "  for opt, dl, err in itertools.product(hparam1['optim_dict'])\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c18b50-8008-461f-9094-c515225fd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using combined hparams and the invariable base dict, create\n",
    "# run dict\n",
    "\n",
    "run_dict = {}\n",
    "for run, hparam_dict in enumerate(combined_hparams):\n",
    "  new_dict = {**invariable_dict, **hparam_dict}\n",
    "  new_dict['hparams'] = hparam_dict\n",
    "  new_dict['run'] = 0\n",
    "  dict_pair = {run: new_dict}\n",
    "  run_dict.update(dict_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f18e03-3573-4ec3-bb89-7fc674a20ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo in main script, replace this with an encapsulating loop, right now keep it simple\n",
    "# init loop variables\n",
    "\n",
    "exp = run_dict[0]\n",
    "\n",
    "# always start by resetting seeds before initializing anythin  g\n",
    "gt.init_seeds(exp['seed'], exp['device'])\n",
    "\n",
    "# prep dataloader, use kwargs to init\n",
    "\n",
    "if exp['dl_dict']['batch_type'] == 'fixed':\n",
    "  batch_size = exp['dl_dict']['batch_size']\n",
    "else:\n",
    "  batch_fraction = exp['dl_dict']['batch_size']\n",
    "  batch_size = int(len(train_label) * batch_fraction)\n",
    "  if batch_size == 0:\n",
    "    batch_size = 1\n",
    "exp['dl_dict'] = {'batch_size': batch_size, 'shuffle': exp['dl_dict']['shuffle']}\n",
    "\n",
    "train_loader = DataLoader(train_set, **exp['dl_dict'])\n",
    "valid_loader = DataLoader(valid_set, batch_size=len(valid_label), shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_label,), shuffle=False)\n",
    "\n",
    "# build model / load state dict / load whole model / explicitly init param weights\n",
    "\n",
    "model_path = f\"{exp['model']}_{exp['init_num']}\"\n",
    "\n",
    "model = models.get_model(exp['model'])()\n",
    "model.load_state_dict(models.load_init_model(model_path))\n",
    "model.to(exp['data_type'])\n",
    "model.to(exp['device'])\n",
    "\n",
    "optim = gt.get_optim(exp['optim'])(model.parameters(), **exp['optim_dict'])\n",
    "error = gt.get_error(exp['error_f'])()\n",
    "\n",
    "profile_model = models.get_model(exp['model'])()\n",
    "profile_model.load_state_dict(models.load_init_model(model_path))\n",
    "profile_model.to(exp['data_type'])\n",
    "profile_model.to(exp['device'])\n",
    "profile_train_loader = DataLoader(train_set, **exp['dl_dict'])\n",
    "\n",
    "# writer doesnt like interior dicts, get rid of them in hparams\n",
    "\n",
    "format_hparams = {**exp['hparams']}\n",
    "\n",
    "for key, value in format_hparams.items():\n",
    "  if isinstance(value, dict):\n",
    "    format_hparams[key] = json.dumps(value)\n",
    "\n",
    "# init tensorboard writer\n",
    "if write:\n",
    "  exp_dir = os.path.join(cwd, exp['exp_dir'])\n",
    "  log = os.path.join(exp_dir, f\"run{exp['run']}\")\n",
    "  train_writer = tb.writer.SummaryWriter(log_dir=log)\n",
    "  test_writer = tb.writer.SummaryWriter(log_dir=os.path.join(log, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4729d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init if rbf\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if preprocess:\n",
    "    kmeans = KMeans(n_clusters=exp['pre_dict']['centers'],\n",
    "                    random_state=exp['seed'])\n",
    "    kmeans.fit(train_data.numpy())\n",
    "    sigmas = [exp['pre_dict']['sigma']] * exp['pre_dict']['centers']\n",
    "    model.post_init(kmeans.cluster_centers_, sigmas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacbd33c-9aa4-4a02-b563-0634ebd8d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for runtime errors / init predictions should be part of data collection loop\n",
    "'''for i in model.parameters():\n",
    "    print(i.dtype)\n",
    "    break\n",
    "print(test_data.dtype)'''\n",
    "\n",
    "with torch.inference_mode():\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca024de-c7a8-417e-bd1d-7d39b41b22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\\n             schedule=torch.profiler.schedule(wait=5, warmup=4, active=1, repeat=1),\\n             on_trace_ready=torch.profiler.tensorboard_trace_handler(os.path.join(log, 'model_profiles')),\\n             record_shapes=True,\\n             with_stack=True,\\n             profile_memory=True) as prof:\\n  with record_function('training'):\\n    for batch_idx, (data, target) in enumerate(train_loader):\\n      pred = model(data)\\n      loss = error(pred, target)\\n      optim.zero_grad()\\n      loss.backward()\\n      optim.step()\\n      prof.step()\\n      alpha = models.newclass.loop_alpha(batch_idx)\\n      if batch_idx == 9:\\n        break\\n\\n  with record_function('inference'):\\n    for batch_idx, (data, target) in enumerate(test_loader):\\n      model(data)\\n      prof.step()\\n      if batch_idx == 9:\\n        break\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# profile model\n",
    "\n",
    "'''with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             schedule=torch.profiler.schedule(wait=5, warmup=4, active=1, repeat=1),\n",
    "             on_trace_ready=torch.profiler.tensorboard_trace_handler(os.path.join(log, 'model_profiles')),\n",
    "             record_shapes=True,\n",
    "             with_stack=True,\n",
    "             profile_memory=True) as prof:\n",
    "  with record_function('training'):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      pred = model(data)\n",
    "      loss = error(pred, target)\n",
    "      optim.zero_grad()\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "      prof.step()\n",
    "      alpha = models.newclass.loop_alpha(batch_idx)\n",
    "      if batch_idx == 9:\n",
    "        break\n",
    "\n",
    "  with record_function('inference'):\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "      model(data)\n",
    "      prof.step()\n",
    "      if batch_idx == 9:\n",
    "        break'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a961cf00-7963-4ee7-a6a7-fc7ba76f5ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with torch.inference_mode():\\n    pred_list = []\\n    target_list = []\\n    total = 0\\n    for batch_idx, (data, target) in enumerate(train_loader):\\n\\n        preds = model(data)\\n        loss = error(preds, target)\\n        pred_list.append(preds)\\n        target_list.append(target)\\n        total += loss\\n    avg_error = total / len(test_data)\\n    gt.write_test_info(exp, train_writer, target_list, pred_l\\nist, avg_error)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init test predictions, to test overall improvement, only needed if model reuse\n",
    "\n",
    "'''with torch.inference_mode():\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        preds = model(data)\n",
    "        loss = error(preds, target)\n",
    "        pred_list.append(preds)\n",
    "        target_list.append(target)\n",
    "        total += loss\n",
    "    avg_error = total / len(test_data)\n",
    "    gt.write_test_info(exp, train_writer, target_list, pred_l\n",
    "ist, avg_error)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e2c20a3-0ef0-4647-aec0-30f3e1d831ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modify_hyper = False\\nif modify_hyper:\\n    epochs = 10\\n    optim = torch.optim.SGD(model.parameters(), lr=0.001, mom\\nentum=0.4)\\n    error = torch.nn.MSELoss()'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify hyperparams, only for model reuse\n",
    "\n",
    "'''modify_hyper = False\n",
    "if modify_hyper:\n",
    "    epochs = 10\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=0.001, mom\n",
    "entum=0.4)\n",
    "    error = torch.nn.MSELoss()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29b9bde5-601d-4507-9430-a9bdea5026ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train and valid, log every epoch\n",
    "\n",
    "error_last = None\n",
    "for epoch in range(exp['stop_dict']['max_epochs']):\n",
    "  model.train()\n",
    "  total = 0\n",
    "  target_list_t = []\n",
    "  pred_list_t = []\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    pred = model(data)\n",
    "    loss = error(pred, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if write:\n",
    "      total += loss\n",
    "      target_list_t.append(target)\n",
    "      pred_list_t.append(pred)\n",
    "  avg_error_t = total / len(train_data)\n",
    "  # todo push batch unpacking to to the writing as to\n",
    "\n",
    "  model.eval()\n",
    "  error_new = None\n",
    "  total = 0\n",
    "  target_list = []\n",
    "  pred_list = []\n",
    "  for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "    pred = model(data)\n",
    "    loss = error(pred, target)\n",
    "    total += loss\n",
    "    if write:\n",
    "      target_list.append(target)\n",
    "      pred_list.append(pred)\n",
    "  avg_error = total / len(valid_data)\n",
    "  \n",
    "  if write:\n",
    "    display.write_classification_train_info(train_writer, model, target_list_t, pred_list_t, avg_error_t, 'train', epoch)\n",
    "    display.write_classification_train_info(train_writer, model, target_list, pred_list, avg_error, 'valid', epoch)\n",
    "\n",
    "  error_new = avg_error\n",
    "  if exp['stop_dict']['criteria'] == 'early_stop':\n",
    "    if error_last is not None and error_new / error_last < exp['stop_dict']['stop_val']:\n",
    "      break\n",
    "    else:\n",
    "      error_last = error_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2a3c84e-c861-49c4-98d5-57131019835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run final inference\n",
    "\n",
    "with torch.inference_mode():\n",
    "  pred_tensor_list = []\n",
    "  target_tensor_list = []\n",
    "  total = 0\n",
    "  for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    preds = model(data)\n",
    "    loss = error(preds, target)\n",
    "    pred_tensor_list.append(preds)\n",
    "    target_tensor_list.append(target)\n",
    "    total += loss\n",
    "  avg_error = total / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e7d2252-0a7a-4273-88ef-b5c38a1f54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': 'cluster_dict.pt', 'exp_dir': 'experiments/cluster/mlp', 'model_type': 'classification', 'device': 'cpu', 'data_type': torch.float32, 'run': 0, 'model': 'mlp1_4', 'init_num': '0', 'optim': 'sgd', 'optim_dict': {'lr': 0.1, 'momentum': 0.4}, 'error_f': 'bce', 'stop_dict': {'criteria': 'epoch', 'stop_val': 0.001, 'max_epochs': 100}, 'dl_dict': {'batch_size': 1, 'shuffle': True}, 'pre_dict': {'centers': 5, 'sigma': 1, 'cluster_algor': 'kmean', 'rbf_init': None}, 'seed': 42, 'hparams': {'model': 'mlp1_4'}}\n"
     ]
    }
   ],
   "source": [
    "# do final tensorboard run write\n",
    "# save preds, labels and state dict\n",
    "# write test info into db\n",
    "cm = display.plot_multiclass_confusion_matrix(target_tensor_list, pred_tensor_list, class_labels)\n",
    "decision_boundary = display.plot_decision_boundary(exp, model, test_data, test_label)\n",
    "print(exp)\n",
    "\n",
    "if write:\n",
    "  train_writer.add_graph(model, train_data)\n",
    "  file_dir = {'preds': pred_list, 'lables': target_list,\n",
    "              'state_dict': model.state_dict(), }\n",
    "  filename = os.path.join(log, 'model_info.pkl')\n",
    "\n",
    "  with open(filename, \"wb\") as file:\n",
    "    pickle.dump(file_dir, file)\n",
    "\n",
    "  train_writer.add_figure('test/confusion_matrix', cm)\n",
    "  train_writer.add_figure('test/decision_boundary', decision_boundary)\n",
    "  display.write_classification_test_info(test_writer, format_hparams, target_tensor_list, pred_tensor_list, avg_error)\n",
    "  # train_writer.add_pr_curve('test/precision_recall_curve', target_tensor, pred_tensor, 0)\n",
    "  train_writer.close()\n",
    "  test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
