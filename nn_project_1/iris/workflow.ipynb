{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f8d0d9577bfce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notes:\n",
    "1. projects must be launched from iris working directory\n",
    "9. integrate tfds into loops\n",
    "13. find more stats for regression analysis\n",
    "14. learn how to use compilers, hooks and registers to speed up processing\n",
    "15. use sampler to increase information quality\n",
    "16. need missed image adder func for the image runs, with image, label and value using tensorboard\n",
    "need decision boundary function for 2d sanity tests, these two can be added when appropriate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.548703Z",
     "start_time": "2024-01-30T03:08:13.454892900Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.utils.tensorboard as tb\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "import general_torch as gt\n",
    "import display\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo initialize dataframe and exp directory here, pass it down to the next part"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b46945857ec500"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo use itertools to generate hparam dictionaries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad98e2efaa30319d"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12800aedc886b754",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.587891800Z",
     "start_time": "2024-01-30T03:08:13.464358600Z"
    }
   },
   "outputs": [],
   "source": [
    "# init exp from scratch\n",
    "# each dictionary represents an individual experiment\n",
    "\n",
    "exp = {}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float\n",
    "exp['model'] = 'model0'\n",
    "exp['model_init_file'] = 'model0_0.pth'\n",
    "exp['optim'] = 'sgd'\n",
    "exp['optim_dict'] = {'lr': 0.1, 'momentum': 0.4}  # if a value is part of the experiment, leave it empty and init it where appropriate\n",
    "exp['error_f'] = 'bce'\n",
    "exp['stop'] = 'epoch'\n",
    "exp['stop_val'] = None\n",
    "exp['max_epoch'] = 100\n",
    "exp['data_file'] = 'iris_tensor_dict.pt'   # put the tensors into one dict and this will be the file extension!\n",
    "exp['dl_dict'] = {'batch_size': 1, 'shuffle': True}  # 'data_batch_size': None, 'random_batch': False,\n",
    "exp['model_type'] = 'classification'  # regression, class\n",
    "exp['seed'] = 42\n",
    "exp['hparams'] = {'lr': 0.1, 'optimizer': 'sgd'}  # todo, exapnd this to include everything, build the optim and dl dicts after\n",
    "exp['device'] = device\n",
    "exp['data_type'] = dtype\n",
    "exp['exp_file'] = f'experiments/troubleshoot_dump'\n",
    "exp['run'] = '4'\n",
    "exp['test_error'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45ac51afdf8cc0b1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.587891800Z",
     "start_time": "2024-01-30T03:08:13.468024600Z"
    }
   },
   "outputs": [],
   "source": [
    "# init profiler log paths\n",
    "cwd = os.getcwd()\n",
    "exp_dir = os.path.join(cwd, exp['exp_file'])\n",
    "train_log= os.path.join(exp_dir, f\"run{exp['run']}\")\n",
    "test_log = os.path.join(exp_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1833066d0443e08d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.475881700Z"
    }
   },
   "outputs": [],
   "source": [
    "# raw data loader, change device, dtype and if needed shape\n",
    "# this needs to change, take exp file, load the dict, use dict to distribute to tensors\n",
    "\n",
    "file_tensor = os.path.join(cwd, f'data/{exp[\"data_file\"]}')\n",
    "\n",
    "dict_tensor = torch.load(file_tensor)\n",
    "\n",
    "train_data = dict_tensor['train_data'].to(exp['device']).to(exp['data_type'])\n",
    "train_label = dict_tensor['train_label'].to(exp['device']).to(exp['data_type'])\n",
    "\n",
    "valid_data = dict_tensor['valid_data'].to(exp['device']).to(exp['data_type'])\n",
    "valid_label = dict_tensor['valid_label'].to(exp['device']).to(exp['data_type'])\n",
    "\n",
    "test_data = dict_tensor['test_data'].to(exp['device']).to(exp['data_type'])\n",
    "test_label = dict_tensor['test_label'].to(exp['device']).to(exp['data_type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af8aeffedfec4b09",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.482372400Z"
    }
   },
   "outputs": [],
   "source": [
    "# init data set\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, train, label):\n",
    "        self.data = train\n",
    "        self.label = label\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "        \n",
    "train_set = Data(train_data, train_label)\n",
    "valid_set = Data(valid_data, valid_label)\n",
    "test_set = Data(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b4dc291a585f6e1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.491460900Z"
    }
   },
   "outputs": [],
   "source": [
    "# always start by resetting seeds before initializing anything\n",
    "gt.init_seeds(exp['seed'], exp['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da455aa1ece1d10f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.500682200Z"
    }
   },
   "outputs": [],
   "source": [
    "# prep dataloader, use kwargs to init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, **exp['dl_dict'])  \n",
    "valid_loader = DataLoader(valid_set, **exp['dl_dict'])\n",
    "test_loader = DataLoader(test_set, **exp['dl_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "932a14f591825c47",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.506007900Z"
    }
   },
   "outputs": [],
   "source": [
    "# build model / load state dict / load whole model / explicitly init param weights\n",
    "import models\n",
    "\n",
    "model = models.get_model(exp['model'])()  \n",
    "model.load_state_dict(models.load_init_model(exp['model_init_file']))  \n",
    "model.to(exp['data_type'])\n",
    "model.to(exp['device'])\n",
    "\n",
    "epochs = exp['max_epoch']\n",
    "optim = gt.get_optim(exp['optim'])(model.parameters(), **exp['optim_dict'])\n",
    "error = gt.get_error(exp['error_f'])()\n",
    "\n",
    "profile_model = models.get_model(exp['model'])()  \n",
    "profile_model.load_state_dict(models.load_init_model(exp['model_init_file'])) \n",
    "profile_model.to(exp['data_type'])\n",
    "profile_model.to(exp['device'])\n",
    "profile_train_loader = DataLoader(train_set, **exp['dl_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b0ac55e6ed340eb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.514738400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daily\\mynn\\nn_project_1\\iris\\models.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# check for runtime errors / init predictions should be part of data collection loop\n",
    "'''for i in model.parameters():\n",
    "    print(i.dtype)\n",
    "    break\n",
    "print(test_data.dtype)'''\n",
    "\n",
    "with torch.inference_mode():  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94f281e0afc4681d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.520062100Z"
    }
   },
   "outputs": [],
   "source": [
    "# init tensorboard\n",
    "# writer needs independent var, trial num, model\n",
    "# write model, params, flops, train time, inference time, memory usage, profiler, can be used here\n",
    "# write trial num, model and independent var\n",
    "\n",
    "train_writer = tb.writer.SummaryWriter(log_dir=train_log)\n",
    "train_writer.add_hparams(exp['hparams'], metric_dict={})  # todo add all params!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# profile model\n",
    "# todo this all was added\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "             schedule=torch.profiler.schedule(wait=5, warmup=4, active=1, repeat=1),\n",
    "             on_trace_ready=torch.profiler.tensorboard_trace_handler(os.path.join(train_log, 'model_profiles')),\n",
    "             record_shapes=True,\n",
    "             with_stack=True,\n",
    "             profile_memory=True) as prof:\n",
    "    \n",
    "    with record_function('training'):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                pred = model(data)\n",
    "                loss = error(pred, target)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                prof.step()\n",
    "                if batch_idx == 9:\n",
    "                    break\n",
    "    \n",
    "    with record_function('inference'):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                model(data)\n",
    "                prof.step()\n",
    "                if batch_idx == 9:\n",
    "                    train_writer.add_graph(model, data)\n",
    "                    break\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "873a4b88a0927a6d"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c501937da37b0069",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.537903500Z"
    }
   },
   "outputs": [],
   "source": [
    "# init test predictions, to test overall improvement, only needed if model reuse\n",
    "\n",
    "'''with torch.inference_mode():  \n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        preds = model(data)\n",
    "        loss = error(preds, target)\n",
    "        pred_list.append(preds)\n",
    "        target_list.append(target)\n",
    "        total += loss\n",
    "    avg_error = total / len(test_data)\n",
    "    gt.write_test_info(exp, train_writer, target_list, pred_list, avg_error)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5633f99d4b5d6eae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:13.631256800Z",
     "start_time": "2024-01-30T03:08:13.552056600Z"
    }
   },
   "outputs": [],
   "source": [
    "# modify hyperparams, only for model reuse\n",
    "\n",
    "'''modify_hyper = False\n",
    "if modify_hyper:\n",
    "    epochs = 10\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.4)\n",
    "    error = torch.nn.MSELoss()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8fa03522939ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for train and valid, log every epoch\n",
    "\n",
    "error_last = None\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    target_list = [] \n",
    "    pred_list = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        pred = model(data)\n",
    "        loss = error(pred, target)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += loss\n",
    "        target_list.append(target)\n",
    "        pred_list.append(pred)\n",
    "    avg_error = total / len(train_data)\n",
    "    display.write_train_info(exp, train_writer, model, target_list, pred_list, avg_error, 'train', epoch)\n",
    "\n",
    "    model.eval()\n",
    "    error_new = None\n",
    "    total = 0\n",
    "    target_list = []\n",
    "    pred_list = []\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        pred = model(data)\n",
    "        error_new = error(pred, target)\n",
    "        total += error_new\n",
    "        target_list.append(target)\n",
    "        pred_list.append(pred)\n",
    "    avg_error = total / len(valid_data)\n",
    "    display.write_train_info(exp, train_writer, model, target_list, pred_list, avg_error, 'valid', epoch)\n",
    "    if exp['stop'] == 'error_change':\n",
    "        if error_last is not None and error_new / error_last < exp['stop_value']:\n",
    "            break\n",
    "        else:\n",
    "            error_last = error_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a10d0f577adbb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run final inference\n",
    "\n",
    "# init test predictions, to test overall improvement\n",
    "\n",
    "with torch.inference_mode():  \n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        preds = model(data)\n",
    "        loss = error(preds, target)\n",
    "        pred_list.append(preds)\n",
    "        target_list.append(target)\n",
    "        total += loss\n",
    "    avg_error = total / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo test confusion matrix and para coord func here, "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca6cb9c2fd7b0577"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "write confusion matrix with custum func\n",
    "\"\"\"\n",
    "display.write_test_info(exp, df, target_list, pred_list, avg_error)\n",
    "train_writer.add_pr_curve('test/precision_recall_curve', target_list, pred_list,0)  # todo just added\n",
    "train_writer.close()  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c25493885de3b8c"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e821e46e8c04b833",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:17.187485100Z",
     "start_time": "2024-01-30T03:08:17.184702800Z"
    }
   },
   "outputs": [],
   "source": [
    "#mkdown for notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a4db72db148222",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:08:17.231075200Z",
     "start_time": "2024-01-30T03:08:17.190330Z"
    }
   },
   "outputs": [],
   "source": [
    "# save trial folder need pred list, model and above mkdown, to the exp['exp_dir']\n",
    "\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "file_dir = {'preds': pred_list, 'lables': target_list, 'exp': exp}\n",
    "filename = os.path.join(exp_dir, 'pred_dir.pkl')\n",
    "\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(file_dir, file)\n",
    "    \n",
    "filename = os.path.join(exp_dir, 'info.txt')\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "    pprint.pprint(exp, file)  # todo store everything as json together in exp dir along with df\n",
    "                                # todo save df in exp dir\n",
    "    \n",
    "filename = os.path.join(exp_dir, f'{exp[\"model\"]}.pth')\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d9a4658d02653",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this ends the trial loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''write parallel coordiante graph using dictionaries\n",
    "write seaborn test bar graphs using pandas df'''\n",
    "\n",
    "# todo final write"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b153f7a5bf46b17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Complete! All data is viewable in tensorboard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6b832f100fc1a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
